{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Off\n",
    "\n",
    "What is a variable you wanted to predict in your last project, but couldn't because it wasn't continuous and wouldn't work for for linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Classification is the process of predicting a qualitative response. Methods used for classification often predict the probability of each of the categories of a qualitative variable as the basis for making the classification. \n",
    "\n",
    "With classification, we can answer questions like:\n",
    "- A person has a set of symptoms that could be attributed to one of three medical conditions. Which one?\n",
    "- Is a transaction fraudulent or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Classification Variables\n",
    "\n",
    "*You are given the BMI of sample of people along with other data like their diet, exercise routine, and demographic factors. BMI is a continuous variable, but how could we structure our data to be a classification problem?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Algorithms\n",
    "\n",
    "\n",
    "In this section of the course we will go over many additional machine learning algorithms.  Some of them are specific to classification problems (k-nearest neighbors, naive bayes classifier), while others can be used with both classification and regression problems (decision tree, support vector machine, etc.).  \n",
    "\n",
    "\n",
    "    - K-Nearest Neighbors\n",
    "    - Logistic Regression\n",
    "    - Ensemble Methods (Random Forest and XGBoost)\n",
    "    - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "There are multiple ways to evlauate a classification model when deciding how it generalizes to unseen data. The most straightforward way is the accuracy score - how many of your predicitons were correct. This score can be misleading though. Imagine a dataset where 90% of the obersvations belong to one class. Well you can get 90% accuracy by just always predicting the dominant class. There are additional scores that evlauate more specificall when you are right or wrong.  \n",
    "\n",
    "**Classification Evlauation Metrics:**\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall \n",
    "    - F1 Score\n",
    "    - AUC Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Considerations\n",
    "\n",
    "- **Class imbalance:** How do you handle when one class dominates your observations. i.e. testing for a disease\n",
    "- **Multiclass problems:** Some models are only made to predict binary categories and you have to do additional steps when predicting between 3 or more groups. \n",
    "- **Multilabel problems:** How do you handle it if the observation can belong to multiple groups. i.e. movie genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a K-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: \n",
    "- To be able to implement a KNN classification model, and utilize a visualization to identify the best value of K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- What is the **K-nearest neighbors** classification model?\n",
    "- How do you use the sklearn grid search function?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors (KNN) classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A simple model that classifies a new data point by looking at the data points 'nearest' to the new data point.\n",
    "- KNN is an non parametric lazy learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lazy learning** or **Instance-based (IB)** learning methods simply store the training examples and postpone the generalization (building a model) until a new instance must be classified or prediction made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-parametric models** assume that the data distribution cannot be defined in\n",
    "terms of such a finite set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the KNN algorithm work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src='images/Knn_step_1.webp' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose P1 is the point, for which label needs to predict. \n",
    "\n",
    "First, you need to decide your size of $K$. $K$ is the number of nearest neighbors you want to tak into account when deciding how to classify the new data point.\n",
    "\n",
    "Next, you need to find the $K$ nearest points. You find the distance between points using distance measures such as Euclidean distance, Hamming distance, Manhattan distance and Minkowski distance. \n",
    "\n",
    "Then you classify new points by 'majority vote' of its $K$ neighbors.  Each object votes for their class and the class with the most votes is taken as the prediction. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/KNN_final.webp' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN has the following basic steps:\n",
    "\n",
    "1. Determin number of neighbors\n",
    "2. Calculate distance\n",
    "3. Find closest neighbors\n",
    "4. Vote for labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example training data\n",
    "\n",
    "This example uses a multi-class problem and each color represents a different class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map (K=1)\n",
    "\n",
    "![1NN classification map](images/04_1nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map (K=5)\n",
    "\n",
    "![5NN classification map](images/04_5nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "\n",
    "**Euclidean distance** refers to the distance between two points. These points can be in different dimensional space and are represented by different forms of coordinates. In one-dimensional space, the points are just on a straight number line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring distance in a 2-d Space\n",
    "\n",
    "In two-dimensional space, the coordinates are given as points on the x- and y-axes\n",
    "\n",
    "![alt text](images/euclidean-distance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring distance in a 3-d Space\n",
    "\n",
    "In three-dimensional space, x-, y- and z-axes are used. \n",
    "\n",
    "$$\\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2 +  (z_1-z_2)^2}$$\n",
    "![alt text](images/vectorgraph.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance Equation\n",
    "![alt text](images/euclidean-equation.png)\n",
    "\n",
    "The source of this formula is in the Pythagorean theorem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting\n",
    "\n",
    "How to break ties:\n",
    "\n",
    "1. When doing a binary classification, often use a odd K to avoid ties.\n",
    "2. Multiple approaches for Multiclass problems:\n",
    "    - Reduce the K by 1 to see who wins.\n",
    "    - Weight the votes based on the distance of the neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the KNN Classifier with SKlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the Titanic dataset again. Instead of showing all of the cleanings steps, I have saved a cleaned version of the data for us to import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv('cleaned_titanic.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that is new is I created a binary variable to classify passengars less than 10 years old.  I now need to convert that boolean into an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['youngin'] = titanic['youngin'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'youngin',\n",
       "       'male', 'Q', 'S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>youngin</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.382452</td>\n",
       "      <td>2.311586</td>\n",
       "      <td>29.019314</td>\n",
       "      <td>0.524184</td>\n",
       "      <td>0.382452</td>\n",
       "      <td>32.096681</td>\n",
       "      <td>0.069741</td>\n",
       "      <td>0.649044</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.724409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.486260</td>\n",
       "      <td>0.834700</td>\n",
       "      <td>13.209814</td>\n",
       "      <td>1.103705</td>\n",
       "      <td>0.806761</td>\n",
       "      <td>49.697504</td>\n",
       "      <td>0.254854</td>\n",
       "      <td>0.477538</td>\n",
       "      <td>0.281427</td>\n",
       "      <td>0.447063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare  \\\n",
       "count  889.000000  889.000000  889.000000  889.000000  889.000000  889.000000   \n",
       "mean     0.382452    2.311586   29.019314    0.524184    0.382452   32.096681   \n",
       "std      0.486260    0.834700   13.209814    1.103705    0.806761   49.697504   \n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.895800   \n",
       "50%      0.000000    3.000000   26.000000    0.000000    0.000000   14.454200   \n",
       "75%      1.000000    3.000000   36.500000    1.000000    0.000000   31.000000   \n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   \n",
       "\n",
       "          youngin        male           Q           S  \n",
       "count  889.000000  889.000000  889.000000  889.000000  \n",
       "mean     0.069741    0.649044    0.086614    0.724409  \n",
       "std      0.254854    0.477538    0.281427    0.447063  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    1.000000    0.000000    1.000000  \n",
       "75%      0.000000    1.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to be used in the models\n",
    "# Create matrix of features\n",
    "X = titanic.drop('Survived', axis = 1) # grabs everything else but 'Survived'\n",
    "\n",
    "# X = titanic[['Age', 'male', 'Q', 'S' ]]\n",
    "\n",
    "# Create target variable\n",
    "y = titanic['Survived'] # y is the column we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 9)\n",
      "(889,)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use x and y variables to split the training data into train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of Scaling\n",
    "\n",
    "Compare how the different the data looks when it is scaled versus non-scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/nonnormal.png' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/normalized.png' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Should we use a Standard Scaler or Min-Max Scaler?\n",
    "\n",
    "https://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "http://datareality.blogspot.com/2016/11/scaling-normalizing-standardizing-which.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn 4-step modeling pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import the class you plan to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** \"Instantiate\" the \"estimator\"\n",
    "\n",
    "- \"Estimator\" is scikit-learn's term for model\n",
    "- \"Instantiate\" means \"make an instance of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name of the object does not matter\n",
    "- Can specify tuning parameters (aka \"hyperparameters\") during this step\n",
    "- All parameters not specified are set to their defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit the model with data (aka \"model training\")\n",
    "\n",
    "- Model is learning the relationship between X and y\n",
    "- Occurs in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Predict the response for a new observation\n",
    "\n",
    "- New observations are called \"out-of-sample\" data\n",
    "- Uses the information it learned during the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8071748878923767\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print('Accuracy:' + str(metrics.accuracy_score(y_test, y_pred_class)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams[\"figure.figsize\"] = [10,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, without normalization\n",
      "[[113  25]\n",
      " [ 18  67]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred_class)\n",
    "classes = ['Perished', 'Survived']\n",
    "plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a different value for K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-be01a5e51114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# fit the model with data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mknn7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# make class predictions for the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# instantiate the model (using a different value fopr K)\n",
    "knn7 = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "\n",
    "# fit the model with data\n",
    "knn7.fit(x_train, y_train)\n",
    "\n",
    "# make class predictions for the testing set\n",
    "y_pred_class = knn7.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:' + str(metrics.accuracy_score(y_class, y_pred_class)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred_class)\n",
    "classes = ['Perished', 'Survived']\n",
    "plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function to search for an optimal value of K for KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1f4c5ea55dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mknn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "#create a container to track the scores\n",
    "k_scores=[]\n",
    "\n",
    "#set up a loop to fit the model using a different values of K\n",
    "\n",
    "k_range = list(range(1, 12))\n",
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    k_scores.append(acc)\n",
    "    \n",
    "    #fit the model and get the score on a evaluation metric\n",
    "\n",
    "    # Print out the scores to see which one is best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual comparison of different $K$s\n",
    "\n",
    "This is not an ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(k_range, k_scores, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Accuracy score by K Value')  \n",
    "plt.xlabel('K Value')  \n",
    "plt.ylabel('Accuracy Score') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What value of K performs best on our Test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you think K size relates to our concepts of bias and variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/K-NN_Neighborhood_Size_print.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Nearest Neighbors](http://scikit-learn.org/stable/modules/neighbors.html) (user guide), [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (class documentation)\n",
    "\n",
    "- [Videos from An Introduction to Statistical Learning](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n",
    "    - Classification Problems and K-Nearest Neighbors (Chapter 2)\n",
    "    - Introduction to Classification (Chapter 4)\n",
    "    - Logistic Regression and Maximum Likelihood (Chapter 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
